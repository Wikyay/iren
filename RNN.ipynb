{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_chars = string.ascii_lowercase + \" \"\n",
    "\n",
    "# Load and preprocess the text data\n",
    "with open(\"pokemon.txt\", \"r\") as f:\n",
    "    lines = [line.strip().lower() for line in f.readlines()]\n",
    "\n",
    "# Filter out unwanted characters\n",
    "lines = [''.join(c for c in line if c in allowed_chars) for line in lines]\n",
    "text = \"\".join(lines)\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = {char: i for i, char in enumerate(chars)}\n",
    "\n",
    "int_text = [char_to_int[char] for char in text]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence, num_categories):\n",
    "    result = torch.zeros((len(sequence), num_categories))\n",
    "    for i, category in enumerate(sequence):\n",
    "        result[i, category] = 1\n",
    "    return result\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden.expand(input.size(0), -1)), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = output_size = len(chars)\n",
    "hidden_size = 1024\n",
    "model = RNN(input_size, hidden_size, output_size)\n",
    "loss_fn = nn.NLLLoss()\n",
    "learning_rate = 0.005\n",
    "num_epochs = 1000\n",
    "batch_size = 128\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden = model.init_hidden()\n",
    "    losses = []\n",
    "    for i in range(0, len(int_text) - batch_size, batch_size):\n",
    "        inputs = one_hot_encode(int_text[i:i+batch_size], input_size)\n",
    "        targets = torch.tensor(int_text[i+1:i+batch_size+1])\n",
    "        outputs, hidden = model(inputs, hidden.detach())\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}: loss={np.mean(losses)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_name(start, name_length):\n",
    "    generated_name = start\n",
    "    hidden = model.init_hidden()\n",
    "    for _ in range(name_length):\n",
    "        input = one_hot_encode([char_to_int[generated_name[-1]]], input_size)\n",
    "        output, hidden = model(input, hidden)\n",
    "        probabilities = torch.exp(output).detach().numpy().flatten()\n",
    "        next_char = np.random.choice(chars, p=probabilities)\n",
    "        generated_name += next_char\n",
    "    return generated_name.capitalize()\n",
    "\n",
    "num_names = 10\n",
    "name_length = 10\n",
    "generated_names = [generate_name('u', name_length) for _ in range(num_names)]\n",
    "print(generated_names)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_file, config_file):\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    config = {\n",
    "        \"input_size\": input_size,\n",
    "        \"hidden_size\": hidden_size,\n",
    "        \"output_size\": output_size,\n",
    "    }\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(config, f)\n",
    "        \n",
    "save_model(model, \"RNN_pokemon.pth\", \"RNN_pokemon_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set the training parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "\n",
    "# Define the parameter grid for hyperparameter search\n",
    "param_grid = {\n",
    "    \"hidden_size\": [128, 256],\n",
    "    \"num_layers\": [1, 2],\n",
    "    \"learning_rate\": [0.01, 0.001],\n",
    "    \"dropout_rate\": [0, 0.5],\n",
    "}\n",
    "\n",
    "# Create a list to store the results of the hyperparameter search\n",
    "results = []\n",
    "\n",
    "# Perform grid search\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = RNN(input_size, params[\"hidden_size\"], output_size, params[\"num_layers\"], params[\"dropout_rate\"]).to(device)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=params[\"learning_rate\"])\n",
    "    \n",
    "    # Create the DataLoader for your training data\n",
    "    # Replace this with your DataLoader implementation\n",
    "    train_dataloader = DataLoader(...)\n",
    "    \n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        train_model(model, train_dataloader, loss_fn, optimizer, device)\n",
    "    \n",
    "    # Create the DataLoader for your validation data\n",
    "    # Replace this with your DataLoader implementation\n",
    "    val_dataloader = DataLoader(...)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    val_loss = evaluate_model(model, val_dataloader, loss_fn, device)\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\"params\": params, \"val_loss\": val_loss})\n",
    "\n",
    "# Find the best hyperparameters\n",
    "best_result = min(results, key=lambda x: x[\"val_loss\"])\n",
    "print(f\"Best hyperparameters: {best_result['params']}\")\n",
    "print(f\"Validation loss: {best_result['val_loss']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
